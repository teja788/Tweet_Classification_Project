{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install clean-text[gpl]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##loading required libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nimport transformers\nimport matplotlib.pyplot as plt\nfrom cleantext import clean\nfrom keras.preprocessing.text import Tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##loading required datasets\ntrain = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsample_submission=pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##This code is for using TPU clusters provided by Kaggle\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping id, location column due to large no of Nan.\n\ntrain.drop(['id','location','keyword'],axis=1,inplace=True)\ntest.drop(['id','location','keyword'],axis=1,inplace=True)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##cleaning the text using clean-text package\n\ndef text_cleaning(text):\n    text=clean(text,\n    fix_unicode=True,               # fix various unicode errors\n    to_ascii=True,                  # transliterate to closest ASCII representation\n    lower=True,                     # lowercase text\n    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n    no_urls=True,                  # replace all URLs with a special token\n    no_emails=True,                # replace all email addresses with a special token\n    no_phone_numbers=True,         # replace all phone numbers with a special token\n    no_numbers=True,               # replace all numbers with a special token\n    no_digits=True,                # replace all digits with a special token\n    no_currency_symbols=True,      # replace all currency symbols with a special token\n    no_punct=True,                 # fully remove punctuation\n    replace_with_url=\"\",\n    replace_with_email=\"\",\n    replace_with_phone_number=\"\",\n    replace_with_number=\"\",\n    replace_with_digit=\"\",\n    replace_with_currency_symbol=\"\",\n    lang=\"en\"                       # set to 'de' for German special handling\n    )\n    return text\n\n#train[\"text\"].map(lambda x: text_cleaning(x))\n#train[\"text\"][7610]\n\ntrain[\"text\"] = train[\"text\"].map(lambda x: text_cleaning(x))\ntest[\"text\"] = test[\"text\"].map(lambda x: text_cleaning(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##tokenizing the words\nword_tokenizer = Tokenizer()\nword_tokenizer.fit_on_texts(train[\"text\"].values)\n\nseq_train = word_tokenizer.texts_to_sequences(train[\"text\"].values)\nseq_test = word_tokenizer.texts_to_sequences(test[\"text\"].values)\n\n#seq_train[7610]\n#word_tokenizer.index_word[2280]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Creating a word index\nword_index = word_tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##padding the sequences\nseq_pad_train = tf.keras.preprocessing.sequence.pad_sequences(seq_train, maxlen=28)\nseq_pad_test = tf.keras.preprocessing.sequence.pad_sequences(seq_test, maxlen=28)\n\nseq_pad_train[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##downloading the glove embeddings\n#!wget http://nlp.stanford.edu/data/glove.6B.zip\n#!unzip -q glove.6B.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Processing embeddings to make embedding matrix\n\nembeddings_index = {}\n#f = open('/kaggle/input/glove-em/glove.6B.100d.txt')\n#f = open('./glove.6B.300d.txt')\nf = open(\"/kaggle/input/glove-300/glove.6B.300d.txt\")\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creation of embedding matrix\n\nEMBEDDING_DIM=300\nembedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating embedding matrix\nfrom keras.layers import Embedding\n\nembedding_layer = Embedding(len(word_index) + 1,\n                            EMBEDDING_DIM,\n                            weights=[embedding_matrix],\n                            input_length=28,\n                            trainable=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creation of network architecure\nwith strategy.scope():\n    # A integer input for vocab indices.\n    inputs = tf.keras.Input(shape=(28,),dtype=\"int32\")\n\n    # Next, we add a layer to map those vocab indices into a space of dimensionality\n    # 'embedding_dim'.\n    x = embedding_layer(inputs)\n\n\n    #x = tf.keras.layers.LSTM(24,return_sequences=True)(x)\n    #x = tf.keras.layers.Dropout(0.2)(x)    \n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,return_sequences=True))(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,return_sequences=True))(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,return_sequences=True))(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100))(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    predictions = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n\n    model = tf.keras.Model(inputs, predictions)\n    model.summary()\n    \n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the model architecture\ntf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the model\nmodel.fit(seq_pad_train, train[\"target\"].values, epochs=20, batch_size=16, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction on test data and submission file creation\nfinal=sample_submission[['id']]\nfinal['target'] = model.predict(seq_pad_test)\n\n\ndef thres(x):\n    if x>=0.5:\n        return 1\n    else:\n        return 0\n    \nfinal['target'] = final['target'].map(lambda x: thres(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.to_csv(\"basic_transfer_14.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}